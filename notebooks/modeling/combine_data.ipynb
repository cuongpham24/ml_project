{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizerFast, DistilBertModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import ceil\n",
    "from numpy import load\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch is using CUDA.\n"
     ]
    }
   ],
   "source": [
    "# Setup backend device\n",
    "if torch.cuda.is_available():\n",
    "    # Check for CUDA (traditional GPUs)\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"PyTorch is using CUDA.\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    # Check for MPS (Apple Silicon GPUs)\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"PyTorch is using MPS.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"PyTorch is using CPU.\")\n",
    "\n",
    "def load_emb_data(file_name):\n",
    "    # load dict of arrays\n",
    "    dict_data = load(f\"../../data/processed/{file_name}.npz\")\n",
    "    # extract the first array\n",
    "    return dict_data['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read index\n",
    "title_index_error = load_emb_data(\"title_index_error\")\n",
    "title_index = load_emb_data(\"title_index\")\n",
    "title_label = load_emb_data(\"title_label\")\n",
    "\n",
    "feature_index_error = load_emb_data(\"feature_index_error\")\n",
    "feature_index = load_emb_data(\"feature_index\")\n",
    "feature_label = load_emb_data(\"feature_label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join error index\n",
    "joined_error_index = np.unique(np.hstack([title_index_error, feature_index_error]))\n",
    "\n",
    "df_title = pd.DataFrame({\"original_index\": title_index, \"label\": title_label})\n",
    "df_feature = pd.DataFrame({\"original_index\": feature_index, \"label\": feature_label})\n",
    "df = df_title.merge(df_feature, how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join_correct = df[~np.isin(df.original_index, joined_error_index)]\n",
    "df_join_correct.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "2    36054\n",
       "0    30132\n",
       "1     5090\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_join_error = df[np.isin(df.original_index, joined_error_index)]\n",
    "df_join_error.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "num_error_select = 5000\n",
    "# Randomly select 5000 data for each category in the error index set\n",
    "selected_id = np.array([])\n",
    "for i in range(3):\n",
    "    temp = df_join_error.original_index[df_join_error.label == i].sample(n=num_error_select).to_numpy()\n",
    "    selected_id = np.hstack([selected_id, temp])\n",
    "\n",
    "num_correct_select = 7500\n",
    "# Randomly select 7500 data for each category in the error index set\n",
    "for i in range(3):\n",
    "    temp = df_join_correct.original_index[df_join_correct.label == i].sample(n=num_correct_select).to_numpy()\n",
    "    selected_id = np.hstack([selected_id, temp])\n",
    "\n",
    "selected_id = selected_id.astype(int)\n",
    "\n",
    "df_select = df[df.original_index.isin(selected_id)]\n",
    "\n",
    "np.savez_compressed(f'../../data/processed/combine_index.npz', df_select.original_index.to_numpy())\n",
    "np.savez_compressed(f'../../data/processed/combine_label.npz', df_select.label.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_bert_vec = load_emb_data(\"title_bert_vec\")\n",
    "selected_vec = title_bert_vec[np.isin(title_index, df_select.original_index)]\n",
    "np.savez_compressed(f'../../data/processed/combine_title.npz', selected_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_bert_vec = load_emb_data(\"feature_bert_vec\")\n",
    "selected_vec = feature_bert_vec[np.isin(feature_index, df_select.original_index)]\n",
    "np.savez_compressed(f'../../data/processed/combine_feature.npz', selected_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
