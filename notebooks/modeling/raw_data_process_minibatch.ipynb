{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from collections import Counter\n",
    "import os\n",
    "from transformers import DistilBertTokenizerFast\n",
    "from math import ceil\n",
    "\n",
    "DATASET = [\"meta_Beauty_and_Personal_Care\", \"meta_Books\", \"meta_Home_and_Kitchen\"]\n",
    "LABELS = [\"personal_care\", \"book\", \"home\"]\n",
    "COLUMN_SELECTIONS = [\"main_category\", \"title\", \"features\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch is using CUDA.\n"
     ]
    }
   ],
   "source": [
    "# Setup backend device\n",
    "if torch.cuda.is_available():\n",
    "    # Check for CUDA (traditional GPUs)\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"PyTorch is using CUDA.\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    # Check for MPS (Apple Silicon GPUs)\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"PyTorch is using MPS.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"PyTorch is using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# documents = []\n",
    "# for label in LABELS:\n",
    "#     # Read the extracted raw data\n",
    "#     df_temp = pd.read_parquet(f\"../../data/raw/{label}.parquet\")\n",
    "#     df_temp.title = df_temp.title.astype(\"str\")\n",
    "#     df_temp.features = df_temp.features.astype(\"str\")\n",
    "#     # Convert text to lower case\n",
    "#     df_temp = df_temp.drop(\"main_category\", axis=1).apply(lambda x: x.str.lower())\n",
    "#     # Append non-empty string to documents\n",
    "#     documents += df_temp.title[df_temp.title != \"\"].to_list()\n",
    "#     documents += df_temp.features[df_temp.features != \"\"].to_list()\n",
    "\n",
    "# print(len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1725905\n"
     ]
    }
   ],
   "source": [
    "documents = []\n",
    "label = LABELS[0]\n",
    "# Read the extracted raw data\n",
    "df_temp = pd.read_parquet(f\"../../data/raw/{label}.parquet\")\n",
    "df_temp.title = df_temp.title.astype(\"str\")\n",
    "df_temp.features = df_temp.features.astype(\"str\")\n",
    "# Convert text to lower case\n",
    "df_temp = df_temp.drop(\"main_category\", axis=1).apply(lambda x: x.str.lower())\n",
    "# Append non-empty string to documents\n",
    "documents += df_temp.title[df_temp.title != \"\"].to_list()\n",
    "documents += df_temp.features[df_temp.features != \"\"].to_list()\n",
    "\n",
    "print(len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "embedding_dim = 256\n",
    "batch_size = 4\n",
    "epochs = 15\n",
    "learning_rate = 0.01\n",
    "context_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get vocabulary\n",
    "vocab = tokenizer.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start 0\n"
     ]
    }
   ],
   "source": [
    "# Generate context-target pairs for CBOW\n",
    "def create_cbow_pairs(documents, context_size, pairs=None, verbose=False):\n",
    "    # If pairs is empty then initialze an empty array\n",
    "    if pairs == None:\n",
    "        pairs = []\n",
    "    for i in range(len(documents)):\n",
    "        doc = tokenizer(documents[i], return_tensors=\"pt\")[\"input_ids\"][0]\n",
    "        if verbose:\n",
    "            if i % 10000 == 0:\n",
    "                print(\"Start\", i)\n",
    "        if len(doc) < context_size:\n",
    "            continue\n",
    "        for i in range(context_size, len(doc) - context_size):\n",
    "            context = doc[i-context_size : i] + doc[i + 1 : i + context_size + 1]\n",
    "            target = doc[i]\n",
    "            pairs.append((context, target))\n",
    "    return pairs\n",
    "\n",
    "\n",
    "# # This loop prepares training data and reduce memory store in documents\n",
    "# minibatch = 100000\n",
    "# original_length = len(documents)\n",
    "# num_iter = ceil(original_length / minibatch)\n",
    "\n",
    "# cbow_pairs = []\n",
    "# print(\"The total of iteration is\", num_iter)\n",
    "# for i in range(num_iter):\n",
    "#     print(f\"Start {i * minibatch}\")\n",
    "#     cutoff = minibatch if minibatch < len(documents) else len(documents)\n",
    "#     cbow_pairs += create_cbow_pairs(documents[:cutoff], context_size)\n",
    "#     # Reduce size of documents\n",
    "#     documents = documents[cutoff:]\n",
    "cbow_pairs = create_cbow_pairs(documents[:100], context_size, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset and Dataloader for CBOW\n",
    "class CBOWDataset(Dataset):\n",
    "    def __init__(self, cbow_pairs, context_size):\n",
    "        self.data = cbow_pairs\n",
    "        self.context_size = context_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        context, target = self.data[idx]\n",
    "        return context, torch.tensor(target, dtype=torch.long)\n",
    "\n",
    "dataset = CBOWDataset(cbow_pairs, context_size)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Architecture\n",
    "class WordEmbeddings(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embeddings = nn.Embedding(num_embeddings=len(vocab), embedding_dim=embedding_dim)\n",
    "        self.linear_1 = nn.Linear(in_features=embedding_dim, out_features=len(vocab))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embeddings(x)\n",
    "        x = x.mean(axis=1)\n",
    "        x = self.linear_1(x)\n",
    "        return x\n",
    "\n",
    "# Training Setup\n",
    "model = WordEmbeddings()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.95)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vpham01\\AppData\\Local\\Temp\\ipykernel_8496\\596410797.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return context, torch.tensor(target, dtype=torch.long)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m feature, label \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[0;32m      6\u001b[0m     model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m----> 7\u001b[0m     feature \u001b[38;5;241m=\u001b[39m \u001b[43mfeature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     label \u001b[38;5;241m=\u001b[39m label\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     10\u001b[0m     y_train_pred \u001b[38;5;241m=\u001b[39m model(feature)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0\n",
    "    model.train()\n",
    "    for feature, label in dataloader:\n",
    "        model = model.to(device)\n",
    "        feature = feature.to(device)\n",
    "        label = label.to(device)\n",
    "\n",
    "        y_train_pred = model(feature)\n",
    "\n",
    "        loss = loss_fn(y_train_pred, label)\n",
    "        train_loss = train_loss + loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss = train_loss / len(dataloader)\n",
    "    print(f\"Epoch:{epoch} | Training Loss : {train_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = model.embeddings.state_dict()['weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_weights = model.embeddings.weight.data.cpu().numpy()\n",
    "# Save the embedding weights to a .npy file\n",
    "np.save('embedding_weights.npy', embedding_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Dataset and Dataloader\n",
    "# class TextDataset(Dataset):\n",
    "#     def __init__(self, tokenized_docs, word_to_idx, max_len=None):\n",
    "#         self.data = [[word_to_idx.get(word, word_to_idx[\"<UNK>\"]) for word in doc] for doc in tokenized_docs]\n",
    "#         if max_len:\n",
    "#             self.max_len = max_len\n",
    "#         else:\n",
    "#             self.max_len = max(len(doc) for doc in self.data)\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.data)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         doc = self.data[idx]\n",
    "#         if len(doc) > self.max_len:\n",
    "#             padded_doc = doc[:self.max_len]\n",
    "#         else:\n",
    "#             padded_doc = doc + [word_to_idx[\"<PAD>\"]] * (self.max_len - len(doc))\n",
    "#         return torch.tensor(padded_doc, dtype=torch.long)\n",
    "\n",
    "# dataset = TextDataset(documents, word_to_idx)\n",
    "# dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
